{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T01:38:11.386645Z",
     "start_time": "2019-02-18T01:38:11.383516Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import  pandas   as pd\n",
    "import  numpy   as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-18T01:38:11.643Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../input/train.csv')\n",
    "df_test = pd.read_csv('../input/test.csv')\n",
    "df_hist_trans = pd.read_csv('../input/historical_transactions.csv',parse_dates=['purchase_date'])\n",
    "df_new_merchant_trans = pd.read_csv('../input/new_merchant_transactions.csv',parse_dates=['purchase_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-18T01:38:12.113Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_hist_trans = df_hist_trans.sort_values(by=['card_id', 'purchase_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-18T01:38:13.963Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new_merchant_trans = df_new_merchant_trans.sort_values(by=['card_id', 'purchase_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-18T01:38:14.858Z"
    }
   },
   "outputs": [],
   "source": [
    "df_hist_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-18T01:38:16.178Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist_df_merchant_text = {}\n",
    "hist_df_merchant_text['card_id']= []\n",
    "hist_df_merchant_text['hist_merchant_text']= []\n",
    "\n",
    "gp = df_hist_trans.groupby(\"card_id\")\n",
    "\n",
    "for  card ,card_df  in  gp:\n",
    "    hist_df_merchant_text['card_id'].append(card)\n",
    "    hist_df_merchant_text['hist_merchant_text'].append(\" \".join(card_df['merchant_id'].astype(str).tolist()))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T17:52:21.533333Z",
     "start_time": "2019-02-17T17:49:58.036649Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df_merchant_text = {}\n",
    "new_df_merchant_text['card_id']= []\n",
    "new_df_merchant_text['new_merchant_text']= []\n",
    "\n",
    "gp = df_new_merchant_trans.groupby(\"card_id\")\n",
    "\n",
    "for  card ,card_df  in  gp:\n",
    "    new_df_merchant_text['card_id'].append(card)\n",
    "    new_df_merchant_text['new_merchant_text'].append(\" \".join(card_df['merchant_id'].astype(str).tolist()))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T17:52:21.839344Z",
     "start_time": "2019-02-17T17:52:21.535078Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist_df_merchant_text =  pd.DataFrame(hist_df_merchant_text)\n",
    "new_df_merchant_text =  pd.DataFrame(new_df_merchant_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T17:52:21.844176Z",
     "start_time": "2019-02-17T17:52:21.841159Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import gensim\n",
    "\n",
    "# train_seg_list =  hist_df_merchant_text.hist_merchant_text.str.split().tolist()+new_df_merchant_text.new_merchant_text.str.split().tolist()\n",
    "\n",
    "# w2v=gensim.models.Word2Vec(sentences=train_seg_list,size=300,min_count=1,workers=24,window=5,iter=50) \n",
    "\n",
    "# w2v.wv.save_word2vec_format(\"../input/merchant_w2v_300.txt\",binary=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T17:52:22.152513Z",
     "start_time": "2019-02-17T17:52:21.845636Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_df_merchant =  pd.merge(hist_df_merchant_text,new_df_merchant_text,how = 'left', on = ['card_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T17:52:22.163220Z",
     "start_time": "2019-02-17T17:52:22.154197Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>hist_merchant_text</th>\n",
       "      <th>new_merchant_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_00007093c1</td>\n",
       "      <td>M_ID_69423b34e4 M_ID_a33355a1b7 M_ID_9400cf234...</td>\n",
       "      <td>M_ID_08f01305af M_ID_00a6ca8a8a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_0001238066</td>\n",
       "      <td>M_ID_d17aabd756 M_ID_d17aabd756 M_ID_d17aabd75...</td>\n",
       "      <td>M_ID_7d8102bb34 M_ID_235e546dcc M_ID_a88790a46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_0001506ef0</td>\n",
       "      <td>M_ID_5b63dd8e8f M_ID_9394291a35 M_ID_a7e436f34...</td>\n",
       "      <td>nan M_ID_ab756f937e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_0001793786</td>\n",
       "      <td>M_ID_7aba38d825 M_ID_f17a1b0efa M_ID_ded236474...</td>\n",
       "      <td>M_ID_4bc2dde1be M_ID_0d406dee2d M_ID_7cdd9d4be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_000183fdda</td>\n",
       "      <td>M_ID_788daa3630 M_ID_788daa3630 M_ID_738e536d5...</td>\n",
       "      <td>M_ID_4af7fb2f08 M_ID_b1eb99fad9 M_ID_c280d42e9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id                                 hist_merchant_text  \\\n",
       "0  C_ID_00007093c1  M_ID_69423b34e4 M_ID_a33355a1b7 M_ID_9400cf234...   \n",
       "1  C_ID_0001238066  M_ID_d17aabd756 M_ID_d17aabd756 M_ID_d17aabd75...   \n",
       "2  C_ID_0001506ef0  M_ID_5b63dd8e8f M_ID_9394291a35 M_ID_a7e436f34...   \n",
       "3  C_ID_0001793786  M_ID_7aba38d825 M_ID_f17a1b0efa M_ID_ded236474...   \n",
       "4  C_ID_000183fdda  M_ID_788daa3630 M_ID_788daa3630 M_ID_738e536d5...   \n",
       "\n",
       "                                   new_merchant_text  \n",
       "0                    M_ID_08f01305af M_ID_00a6ca8a8a  \n",
       "1  M_ID_7d8102bb34 M_ID_235e546dcc M_ID_a88790a46...  \n",
       "2                                nan M_ID_ab756f937e  \n",
       "3  M_ID_4bc2dde1be M_ID_0d406dee2d M_ID_7cdd9d4be...  \n",
       "4  M_ID_4af7fb2f08 M_ID_b1eb99fad9 M_ID_c280d42e9...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df_merchant.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T17:52:22.519198Z",
     "start_time": "2019-02-17T17:52:22.164777Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_merchant_text  =  pd.merge(df_train[['card_id','target']],all_df_merchant,how = 'left',on =['card_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T17:52:22.760466Z",
     "start_time": "2019-02-17T17:52:22.520853Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test_merchant_text  =  pd.merge(df_test[['card_id']],all_df_merchant,how = 'left',on =['card_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T17:52:22.771933Z",
     "start_time": "2019-02-17T17:52:22.762149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "      <th>hist_merchant_text</th>\n",
       "      <th>new_merchant_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>-0.820283</td>\n",
       "      <td>M_ID_1a81c358a3 M_ID_1a81c358a3 M_ID_cc72dac89...</td>\n",
       "      <td>M_ID_56086ccdb1 M_ID_2637773dd2 M_ID_e1fd26e37...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>0.392913</td>\n",
       "      <td>M_ID_d13262f4b0 M_ID_2637773dd2 M_ID_35c84c8ec...</td>\n",
       "      <td>M_ID_4dbadbd1c9 M_ID_6e7c412a33 M_ID_7e93847d9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>M_ID_efd85d1f38 M_ID_14275fe7b9 M_ID_5634fd83e...</td>\n",
       "      <td>M_ID_c84d28e906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>0.142495</td>\n",
       "      <td>M_ID_6dbaf215eb M_ID_26d4fadb60 M_ID_9a06a8cf3...</td>\n",
       "      <td>M_ID_aa13f8b4d9 M_ID_46534664f2 M_ID_a3196b9d3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>-0.159749</td>\n",
       "      <td>M_ID_9f99aa4a8f M_ID_331b7a704b M_ID_48257bb85...</td>\n",
       "      <td>M_ID_8442c31b02 M_ID_07c4c547b5 M_ID_40e0130f8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id    target  \\\n",
       "0  C_ID_92a2005557 -0.820283   \n",
       "1  C_ID_3d0044924f  0.392913   \n",
       "2  C_ID_d639edf6cd  0.688056   \n",
       "3  C_ID_186d6a6901  0.142495   \n",
       "4  C_ID_cdbd2c0db2 -0.159749   \n",
       "\n",
       "                                  hist_merchant_text  \\\n",
       "0  M_ID_1a81c358a3 M_ID_1a81c358a3 M_ID_cc72dac89...   \n",
       "1  M_ID_d13262f4b0 M_ID_2637773dd2 M_ID_35c84c8ec...   \n",
       "2  M_ID_efd85d1f38 M_ID_14275fe7b9 M_ID_5634fd83e...   \n",
       "3  M_ID_6dbaf215eb M_ID_26d4fadb60 M_ID_9a06a8cf3...   \n",
       "4  M_ID_9f99aa4a8f M_ID_331b7a704b M_ID_48257bb85...   \n",
       "\n",
       "                                   new_merchant_text  \n",
       "0  M_ID_56086ccdb1 M_ID_2637773dd2 M_ID_e1fd26e37...  \n",
       "1  M_ID_4dbadbd1c9 M_ID_6e7c412a33 M_ID_7e93847d9...  \n",
       "2                                    M_ID_c84d28e906  \n",
       "3  M_ID_aa13f8b4d9 M_ID_46534664f2 M_ID_a3196b9d3...  \n",
       "4  M_ID_8442c31b02 M_ID_07c4c547b5 M_ID_40e0130f8...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_merchant_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T17:52:22.782111Z",
     "start_time": "2019-02-17T17:52:22.773503Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>hist_merchant_text</th>\n",
       "      <th>new_merchant_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>M_ID_26c089d552 M_ID_9139332ccc M_ID_85a580316...</td>\n",
       "      <td>M_ID_4942754bdb M_ID_963c3bc06b M_ID_be0a17ad20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>M_ID_ea776a9040 M_ID_c3ba8a0906 M_ID_fbb2a5acf...</td>\n",
       "      <td>M_ID_dfdd222b6e M_ID_8e609ef86e M_ID_8de969b57...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>M_ID_3c7f08ddd2 M_ID_a3f84552ad M_ID_c708cbb89...</td>\n",
       "      <td>M_ID_46b3480064 M_ID_86be58d7e0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>M_ID_a085b88f1b M_ID_6a0e5275bb M_ID_5aee6a6c8...</td>\n",
       "      <td>M_ID_2073148bed M_ID_450b1e90a4 M_ID_a9d91682a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>M_ID_d895cb84ae M_ID_d895cb84ae M_ID_d895cb84a...</td>\n",
       "      <td>M_ID_51e3acd8b1 M_ID_255bc75465 M_ID_143451f30...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id                                 hist_merchant_text  \\\n",
       "0  C_ID_0ab67a22ab  M_ID_26c089d552 M_ID_9139332ccc M_ID_85a580316...   \n",
       "1  C_ID_130fd0cbdd  M_ID_ea776a9040 M_ID_c3ba8a0906 M_ID_fbb2a5acf...   \n",
       "2  C_ID_b709037bc5  M_ID_3c7f08ddd2 M_ID_a3f84552ad M_ID_c708cbb89...   \n",
       "3  C_ID_d27d835a9f  M_ID_a085b88f1b M_ID_6a0e5275bb M_ID_5aee6a6c8...   \n",
       "4  C_ID_2b5e3df5c2  M_ID_d895cb84ae M_ID_d895cb84ae M_ID_d895cb84a...   \n",
       "\n",
       "                                   new_merchant_text  \n",
       "0    M_ID_4942754bdb M_ID_963c3bc06b M_ID_be0a17ad20  \n",
       "1  M_ID_dfdd222b6e M_ID_8e609ef86e M_ID_8de969b57...  \n",
       "2                    M_ID_46b3480064 M_ID_86be58d7e0  \n",
       "3  M_ID_2073148bed M_ID_450b1e90a4 M_ID_a9d91682a...  \n",
       "4  M_ID_51e3acd8b1 M_ID_255bc75465 M_ID_143451f30...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_merchant_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T17:52:34.509179Z",
     "start_time": "2019-02-17T17:52:22.783744Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_merchant_text.to_csv(\"../input/df_train_merchant_text\",index = False)\n",
    "df_test_merchant_text.to_csv(\"../input/df_test_merchant_text\",index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T17:52:35.502388Z",
     "start_time": "2019-02-17T17:52:34.510883Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_merchant_text['all_text'] = df_train_merchant_text['hist_merchant_text']+\" O \"+df_train_merchant_text['new_merchant_text']\n",
    "\n",
    "df_test_merchant_text['all_text'] =  df_test_merchant_text['hist_merchant_text']+\" 0 \"+df_train_merchant_text['new_merchant_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T17:52:36.490625Z",
     "start_time": "2019-02-17T17:52:35.504368Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_merchant_text['len'] =  df_train_merchant_text.all_text.map(lambda x:len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T17:52:36.822501Z",
     "start_time": "2019-02-17T17:52:36.492377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f186acead68>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nASNvMZVoyjb0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f18b2b1b0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import seaborn  as  sns\n",
    "\n",
    "sns.kdeplot(df_train_merchant_text['len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T17:52:38.618974Z",
     "start_time": "2019-02-17T17:52:36.824540Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T17:52:38.744152Z",
     "start_time": "2019-02-17T17:52:38.620852Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = df_train_merchant_text[\"all_text\"].fillna(\"_##_\").values\n",
    "test_X =  df_test_merchant_text[\"all_text\"].fillna(\"_##_\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T17:54:11.981824Z",
     "start_time": "2019-02-17T17:52:38.746443Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 500\n",
    "## Tokenize the sentences\n",
    "tokenizer = Tokenizer(num_words=340000)\n",
    "tokenizer.fit_on_texts(list(train_X)+list(test_X))\n",
    "train_X = tokenizer.texts_to_sequences(train_X)\n",
    "test_X = tokenizer.texts_to_sequences(test_X)\n",
    "\n",
    "## Pad the sentences \n",
    "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
    "test_X = pad_sequences(test_X, maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T17:54:34.688380Z",
     "start_time": "2019-02-17T17:54:11.983522Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add static feature\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"./data/pre_train_clip.csv\", index_col=0)\n",
    "train.drop(columns=[\n",
    "    'hist_first_year', 'hist_first_quarter', 'hist_first_month',\n",
    "    'hist_now_year', 'hist_now_quarter', 'hist_now_month',\n",
    "    \n",
    "    'hist_installments_sum', 'hist_i_vs_p2p',\n",
    "    'new_installments_sum', 'new_i_vs_p2p',\n",
    "    'c_i_diff', 'p2p_i_diff',\n",
    "    'c_i_diff_vs', 'p2p_i_diff_vs',\n",
    "\n",
    "#     'hist_sleep', 'hist_sleep_vs_count', 'hist_sleep_vs_p2p',\n",
    "#     'new_sleep', 'new_sleep_vs_count', 'new_sleep_vs_p2p',\n",
    "#     'c_sleep_diff', 'p2p_sleep_diff', \n",
    "    \n",
    "#     'c_p2p_diff_vs', 'c_sleep_diff_vs', 'c_p_diff_vs', \n",
    "#     'p2p_count_diff_vs', 'p2p_sleep_diff_vs', 'p2p_p_diff_vs', \n",
    "                   ], inplace=True)\n",
    "\n",
    "test = pd.read_csv(\"./data/pre_test_clip.csv\", index_col=0)\n",
    "test.drop(columns=[\n",
    "    'hist_first_year', 'hist_first_quarter', 'hist_first_month',\n",
    "    'hist_now_year', 'hist_now_quarter', 'hist_now_month',\n",
    "    \n",
    "    'hist_installments_sum', 'hist_i_vs_p2p',\n",
    "    'new_installments_sum', 'new_i_vs_p2p',\n",
    "    'c_i_diff', 'p2p_i_diff',\n",
    "    'c_i_diff_vs', 'p2p_i_diff_vs',\n",
    "\n",
    "#     'hist_sleep', 'hist_sleep_vs_count', 'hist_sleep_vs_p2p',\n",
    "#     'new_sleep', 'new_sleep_vs_count', 'new_sleep_vs_p2p',\n",
    "#     'c_sleep_diff', 'p2p_sleep_diff', \n",
    "    \n",
    "#     'c_p2p_diff_vs', 'c_sleep_diff_vs', 'c_p_diff_vs', \n",
    "#     'p2p_count_diff_vs', 'p2p_sleep_diff_vs', 'p2p_p_diff_vs', \n",
    "                   ], inplace=True)\n",
    "\n",
    "cats = [\n",
    "        'feature_1', 'feature_2', 'feature_3', \n",
    "#         'hist_first_year', \n",
    "#         'hist_first_quarter', \n",
    "#         'hist_first_month',\n",
    "        'hist_re_year', \n",
    "        'hist_re_quarter', \n",
    "#         'hist_re_month',\n",
    "#         'hist_now_year', \n",
    "#         'hist_now_quarter', \n",
    "#         'hist_now_month',\n",
    "       ]\n",
    "\n",
    "train[cats] = train[cats].fillna(-1, )\n",
    "test[cats] = test[cats].fillna(-1, )\n",
    "\n",
    "features = ['feature_1', 'feature_2', 'authorized_flag_mean', 'hist_transactions_count', 'hist_is_month_start_mean', 'hist_category_1_mean', 'hist_merchant_category_id_nunique', 'hist_merchant_id_nunique', 'hist_month_nunique', 'hist_weekofyear_nunique', 'hist_day_nunique', 'hist_a2p_mean', 'hist_a2p_median', 'hist_a2p_min', 'hist_p2now_max', 'hist_purchase_amount_sum', 'hist_installments_mean', 'hist_installments_max', 'hist_installments_min', 'hist_p_vs_m_mean', 'hist_p_vs_m_std', 'hist_p_vs_i_median', 'hist_purchase_date_max', 'hist_purchase_date_min', 'hist_category_2_p_mean_std', 'hist_category_3_p_mean_mean', 'hist_category_3_p_mean_max', 'hist_state_id_p_mean_std', 'hist_subsector_id_p_mean_min', 'hist_merchant_id_p_mean_median', 'hist_merchant_id_p_mean_max', 'hist_merchant_id_p_mean_min', 'hist_hour_p_mean_min', 'hist_re_year', 'hist_re_quarter', 'hist_re_month', 'hist_a2r', 'hist_r2now', 'hist_a2now', 'hist_p2p', 'hist_count_vs_p2p', 'hist_sleep_vs_p2p', 'hist_p_vs_p2p', 'new_transactions_count', 'new_category_1_mean', 'new_subsector_id_nunique', 'new_merchant_category_id_nunique', 'new_merchant_id_nunique', 'new_month_nunique', 'new_a2p_mean', 'new_a2p_std', 'new_p2r_mean', 'new_p2r_max', 'new_p2r_min', 'new_p2r_std', 'new_p2now_mean', 'new_p2now_max', 'new_p2now_min', 'new_p2now_std', 'new_month_lag_std', 'new_purchase_amount_max', 'new_purchase_amount_min', 'new_installments_min', 'new_p_vs_m_max', 'new_p_vs_m_min', 'new_p_vs_i_mean', 'new_purchase_date_max', 'new_purchase_date_min', 'new_category_3_p_mean_mean', 'new_quarter_p_mean_mean', 'new_month_p_mean_max', 'new_dayofweek_p_mean_max', 'new_hour_p_mean_min', 'new_sleep_vs_count', 'new_count_vs_p2p', 'c_sleep_diff', 'c_p_diff', 'p2p_p_diff', 'c_p2p_diff_vs', 'c_sleep_diff_vs', 'p2p_count_diff_vs']\n",
    "cat_feats = ['feature_1', 'feature_2', 'hist_re_year', 'hist_re_quarter']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T17:54:35.491946Z",
     "start_time": "2019-02-17T17:54:34.690010Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n",
      "/home/d/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/d/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/d/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/d/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201917, 14) (123623, 14)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import  OneHotEncoder\n",
    "from sklearn.preprocessing import  LabelEncoder\n",
    "import scipy.sparse as sp\n",
    "\n",
    "\n",
    "all_df = pd.concat([train,test])\n",
    "\n",
    "for idx,i in enumerate(cat_feats):\n",
    "    lb = LabelEncoder()\n",
    "    lb.fit(all_df[i])\n",
    "    train[i] = lb.transform(train[i])\n",
    "    test[i] = lb.transform(test[i])\n",
    "    \n",
    "    ohe = OneHotEncoder()\n",
    "    ohe.fit(all_df[i].values.reshape(-1,1))\n",
    "    \n",
    "    tr_x = ohe.transform(train[i].values.reshape(-1,1))\n",
    "    te_x = ohe.transform(test[i].values.reshape(-1,1))\n",
    "    \n",
    "    if idx ==0:\n",
    "        ohe_train_x = tr_x\n",
    "        ohe_test_x = te_x\n",
    "    else:\n",
    "        ohe_train_x = sp.hstack((ohe_train_x,tr_x))\n",
    "        ohe_test_x = sp.hstack((ohe_test_x,te_x))\n",
    "        \n",
    "print(ohe_train_x.shape,ohe_test_x.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T17:54:35.724160Z",
     "start_time": "2019-02-17T17:54:35.493564Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201917, 91) (123623, 91)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "features = [i for i in features if i not in cat_feats]\n",
    "static_train_x = np.hstack((train[features],ohe_train_x.toarray()))\n",
    "static_test_x = np.hstack((test[features],ohe_test_x.toarray()))\n",
    "\n",
    "print(static_train_x.shape,static_test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T17:54:35.745245Z",
     "start_time": "2019-02-17T17:54:35.725775Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_w2v(word_index,max_words=340000, embed_size=300):\n",
    "    EMBEDDING_FILE = '../input/merchant_w2v_300.txt'\n",
    "    emb_mean, emb_std = -0.005838499, 0.48782197\n",
    "\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (max_words, embed_size))\n",
    "    with open(EMBEDDING_FILE, 'r', encoding=\"utf8\",errors='ignore') as f:\n",
    "        for line in f:\n",
    "            word, vec = line.split(' ', 1)\n",
    "            if word not in word_index:\n",
    "                continue\n",
    "            i = word_index[word]\n",
    "            if i >= max_words:\n",
    "                continue\n",
    "            embedding_vector = np.asarray(vec.split(' '), dtype='float32')[:300]\n",
    "            if len(embedding_vector) == 300:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T17:54:42.145856Z",
     "start_time": "2019-02-17T17:54:35.747100Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = load_w2v(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T17:54:43.478179Z",
     "start_time": "2019-02-17T17:54:42.147534Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.layers import GlobalAveragePooling1D,GlobalMaxPooling1D,concatenate,BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras import optimizers\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def squash(x, axis=-1):\n",
    "    # s_squared_norm is really small\n",
    "    # s_squared_norm = K.sum(K.square(x), axis, keepdims=True) + K.epsilon()\n",
    "    # scale = K.sqrt(s_squared_norm)/ (0.5 + s_squared_norm)\n",
    "    # return scale * x\n",
    "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True)\n",
    "    scale = K.sqrt(s_squared_norm + K.epsilon())\n",
    "    return x / scale\n",
    "# A Capsule Implement with Pure Keras\n",
    "class Capsule(Layer):\n",
    "    def __init__(self, num_capsule, dim_capsule, routings=3, kernel_size=(9, 1), share_weights=True,\n",
    "                 activation='default', **kwargs):\n",
    "        super(Capsule, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.kernel_size = kernel_size\n",
    "        self.share_weights = share_weights\n",
    "        if activation == 'default':\n",
    "            self.activation = squash\n",
    "        else:\n",
    "            self.activation = Activation(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(Capsule, self).build(input_shape)\n",
    "        input_dim_capsule = input_shape[-1]\n",
    "        if self.share_weights:\n",
    "            self.W = self.add_weight(name='capsule_kernel',\n",
    "                                     shape=(1, input_dim_capsule,\n",
    "                                            self.num_capsule * self.dim_capsule),\n",
    "                                     # shape=self.kernel_size,\n",
    "                                     initializer='glorot_uniform',\n",
    "                                     trainable=True)\n",
    "        else:\n",
    "            input_num_capsule = input_shape[-2]\n",
    "            self.W = self.add_weight(name='capsule_kernel',\n",
    "                                     shape=(input_num_capsule,\n",
    "                                            input_dim_capsule,\n",
    "                                            self.num_capsule * self.dim_capsule),\n",
    "                                     initializer='glorot_uniform',\n",
    "                                     trainable=True)\n",
    "\n",
    "    def call(self, u_vecs):\n",
    "        if self.share_weights:\n",
    "            u_hat_vecs = K.conv1d(u_vecs, self.W)\n",
    "        else:\n",
    "            u_hat_vecs = K.local_conv1d(u_vecs, self.W, [1], [1])\n",
    "\n",
    "        batch_size = K.shape(u_vecs)[0]\n",
    "        input_num_capsule = K.shape(u_vecs)[1]\n",
    "        u_hat_vecs = K.reshape(u_hat_vecs, (batch_size, input_num_capsule,\n",
    "                                            self.num_capsule, self.dim_capsule))\n",
    "        u_hat_vecs = K.permute_dimensions(u_hat_vecs, (0, 2, 1, 3))\n",
    "        # final u_hat_vecs.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n",
    "\n",
    "        b = K.zeros_like(u_hat_vecs[:, :, :, 0])  # shape = [None, num_capsule, input_num_capsule]\n",
    "        for i in range(self.routings):\n",
    "            b = K.permute_dimensions(b, (0, 2, 1))  # shape = [None, input_num_capsule, num_capsule]\n",
    "            c = K.softmax(b)\n",
    "            c = K.permute_dimensions(c, (0, 2, 1))\n",
    "            b = K.permute_dimensions(b, (0, 2, 1))\n",
    "            outputs = self.activation(tf.keras.backend.batch_dot(c, u_hat_vecs, [2, 2]))\n",
    "            if i < self.routings - 1:\n",
    "                b = tf.keras.backend.batch_dot(outputs, u_hat_vecs, [2, 3])\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.num_capsule, self.dim_capsule)\n",
    "\n",
    "class AttentionWeightedAverage(Layer):\n",
    "    \"\"\"\n",
    "    Computes a weighted average of the different channels across timesteps.\n",
    "    Uses 1 parameter pr. channel to compute the attention value for a single timestep.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, return_attention=False, **kwargs):\n",
    "        self.init = initializers.get('uniform')\n",
    "        self.supports_masking = True\n",
    "        self.return_attention = return_attention\n",
    "        super(AttentionWeightedAverage, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_spec = [InputSpec(ndim=3)]\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[2], 1),\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 initializer=self.init)\n",
    "        self.trainable_weights = [self.W]\n",
    "        super(AttentionWeightedAverage, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        # computes a probability distribution over the timesteps\n",
    "        # uses 'max trick' for numerical stability\n",
    "        # reshape is done to avoid issue with Tensorflow\n",
    "        # and 1-dimensional weights\n",
    "        logits = K.dot(x, self.W)\n",
    "        x_shape = K.shape(x)\n",
    "        logits = K.reshape(logits, (x_shape[0], x_shape[1]))\n",
    "        ai = K.exp(logits - K.max(logits, axis=-1, keepdims=True))\n",
    "\n",
    "        # masked timesteps have zero weight\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            ai = ai * mask\n",
    "        att_weights = ai / (K.sum(ai, axis=1, keepdims=True) + K.epsilon())\n",
    "        weighted_input = x * K.expand_dims(att_weights)\n",
    "        result = K.sum(weighted_input, axis=1)\n",
    "        if self.return_attention:\n",
    "            return [result, att_weights]\n",
    "        return result\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return self.compute_output_shape(input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_len = input_shape[2]\n",
    "        if self.return_attention:\n",
    "            return [(input_shape[0], output_len), (input_shape[0], input_shape[1])]\n",
    "        return (input_shape[0], output_len)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        if isinstance(input_mask, list):\n",
    "            return [None] * len(input_mask)\n",
    "        else:\n",
    "            return None\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T17:54:43.538158Z",
     "start_time": "2019-02-17T17:54:43.479974Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_lstm_atten(features,embedding_matrix):\n",
    "    max_features =  340000\n",
    "    embed_size   =  300\n",
    "    features_input = Input(shape=(features.shape[1],))\n",
    "    inp = Input(shape=(maxlen,))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "\n",
    "    rnn= Bidirectional(CuDNNLSTM(50,return_sequences=True))(x)\n",
    "\n",
    "    cnn1 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(rnn)\n",
    "    cnn2 = Conv1D(filters=64, kernel_size=4, activation='relu', padding='same')(rnn)\n",
    "    cnn3 = Conv1D(filters=64, kernel_size=5, activation='relu', padding='same')(rnn)\n",
    "    x = concatenate([rnn, cnn1, cnn2, cnn3])\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    attn = AttentionWeightedAverage()(x)\n",
    "    x = concatenate([avg_pool, max_pool, attn,features_input])\n",
    "\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(300,activation='elu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    outp = Dense(1, activation=\"linear\")(x) \n",
    "\n",
    "    model = Model(inputs=[inp,features_input], outputs=outp)\n",
    "    model.compile(loss='rmse', optimizer='adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T17:54:43.698867Z",
     "start_time": "2019-02-17T17:54:43.540053Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_merchant_text['outliers'] = 0\n",
    "df_train_merchant_text.loc[df_train['target'] < -30, 'outliers'] = 1\n",
    "train_y = df_train_merchant_text['outliers'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T17:54:43.944790Z",
     "start_time": "2019-02-17T17:54:43.700541Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-2ea966c4d9d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midtrain_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midtest_X\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m  \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" %s \"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mtr_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtr_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midtrain_X\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midtrain_X\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    329\u001b[0m                 .format(self.n_splits, n_samples))\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_BaseKFold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m         \u001b[0mtest_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_make_test_folds\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    634\u001b[0m             raise ValueError(\n\u001b[1;32m    635\u001b[0m                 'Supported target types are: {}. Got {!r} instead.'.format(\n\u001b[0;32m--> 636\u001b[0;31m                     allowed_target_types, type_of_target_y))\n\u001b[0m\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead."
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    " \n",
    "from sklearn.model_selection import  StratifiedKFold\n",
    "import numpy as np\n",
    "from sklearn.svm import  LinearSVC\n",
    "from sklearn.metrics import  f1_score\n",
    "NFOLD=5\n",
    "cnn_oof_train=np.zeros((train_X.shape[0],1))\n",
    "cnn_oof_test=np.zeros((test_X.shape[0],1))\n",
    "cnn_oof_test_skf=np.zeros((NFOLD,test_X.shape[0],1))\n",
    "f1_csv=[]\n",
    "skf=StratifiedKFold(n_splits=NFOLD,shuffle=True,random_state=4590)\n",
    "K.clear_session()\n",
    "tf.reset_default_graph()\n",
    "for i,(idtrain_X,idtest_X) in  enumerate(skf.split(train_X,train_y)):\n",
    "    print(\" %s \"%(i+1))\n",
    "    tr_x,tr_y=train_X[idtrain_X],train_y[idtrain_X]\n",
    "    te_x,te_y=train_X[idtest_X],train_y[idtest_X]\n",
    "    tr_features =  static_train_x[idtrain_X]\n",
    "    te_features =  static_train_x[idtest_X]\n",
    "    model = model_lstm_atten(embedding_matrix)\n",
    "    early_stopping = EarlyStopping(monitor=\"val_loss\", patience=2)\n",
    "    best_model_path = \"best_t_weight.h5\"\n",
    "    model_checkpoint = ModelCheckpoint(best_model_path, save_best_only=True, save_weights_only=True)\n",
    "    model.fit([tr_x,tr_features], tr_y, \n",
    "              batch_size= 512, \n",
    "              epochs=20,\n",
    "              shuffle=True,\n",
    "              validation_data=([te_x,te_features],te_y),\n",
    "             callbacks=[model_checkpoint, early_stopping])\n",
    "    val_y=model.predict([te_x,te_features])\n",
    "    cnn_oof_train[idtest_X]=val_y\n",
    "    cnn_oof_test_skf[i:,]=model.predict([test_X,static_test_x])\n",
    "    K.clear_session()\n",
    "    tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
